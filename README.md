# reviewsum

Do you ever feel like you are getting flooded with an increasing amount of articles and links and
videos to choose from? As this data grows the importance of semantic density does as well?
How can you say the most important things in shortest amount of time? Having a generated
summary lets you decide whether you want to deep dive further or not and the better it gets the
more we will be able to apply this in more complex language, like that in scientific paper or in
an entire book.

Most summarisation tools in the past were extracted, they selected an existing subset of number
of words from some data to create a summary. When we summarize, our brain builds an internal
semantic representation of what we have just read from that, we can generate a summary. This
is instead an abstractive method and we can do this with deep learning using natural language
understanding.

In this project we have used an abstractive method for text summarization using natural lan-
guage processing on data available on product/service reviewâ€™s website. Data was made avail-
able using web scraping and machine learning model summarized that review/data and gave proper conclusion.
